# this is a config file to mimic joint learning at a single node where all data is accessible.
common:
  random_seed: 1314
  num_workers: 4
  dataset:
    name: fundus
    kwargs:
      task: segmentation
      num_classes: 3
      root_path: /home/user/data/fundus
      img_size: [ 64, 64 ]
      use_roi: true
      out_range: [ -1.0, 1.0 ]
      num_replica: 10
  strategy:
    name: baseline
    kwargs:
      rgb_inputs: true
  model:
    name: U-Net
    kwargs:
      pretrain: True
      in_channels: 3
      num_classes: 3
      bilinear: false
      backbone: resnet18
  train:
    num_mimgs: 10
    batch_size: 128
    joint_training: true
    precision: 32
    loss:
      name: ExpLogLoss
      kwargs:
        soft_dice: true
        dice_kwargs:
          do_bg: false
          batch_dice: true
        wce_kwargs:
          weight: [ 1, 2, 2 ]
        gamma: 0.3
    optimizer:
      name: Adam
      kwargs:
        lr: 0.001
      lr_scheduler: null
    gradient_clip: 0.0
    check_val_every_n_epoch: 10
    log_every_n_steps: 10

# All tasks that can be tested. Each of these tasks will replace 'dataset' field in 'common' field in a task.
all_tasks_datasets:
  - kwargs:
      task_id: 1
      task_name: Domain1
      img_folder: Domain1
  - kwargs:
      task_id: 2
      task_name: Domain2
      img_folder: Domain2
  - kwargs:
      task_id: 3
      task_name: Domain3
      img_folder: Domain3
  - kwargs:
      task_id: 4
      task_name: Domain4
      img_folder: Domain4
# only train at the first node where all data above is used to train
current_tasks:
  task_ids: [ 1 ]
  task_confs:
    1:
      model:
        kwargs:
          pretrain: True
      checkpoint:
        load: null  # when begin another task
        resume: null  # when resume in the same task
        save:
          dir: task_1  # where to save the model, which can be relayed to the next site
